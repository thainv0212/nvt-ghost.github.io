<!DOCTYPE html>
<html ⚡>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">

    <title>Đi tìm cội nguồn của DeepLearning - Perceptron</title>

    <link rel="canonical" href="../index.html" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    
    <meta property="og:site_name" content="GMO-Z.com Vietnam Lab Center Technology Blog" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Đi tìm cội nguồn của DeepLearning - Perceptron" />
    <meta property="og:description" content="Hẳn là ai cũng biết sông bắt nguồn từ suối, các hồ nước từ độ cao lớn hơn. Và chắc hẳn nhiều người đã biết đến DeepLearning hoặc đã, đang làm việc với DeepLearning tuy nhiên bạn có biết nguồn gốc của DeepLearning(Neural Network)　từ đâu mà có không" />
    <meta property="og:url" content="https://blog.vietnamlab.vn/di-tim-coi-nguon-cua-deeplearning-perceptron/" />
    <meta property="og:image" content="https://drive.google.com/uc?id&#x3D;1mlsY5OD58Y9jLMDA9ikW4CNRkcZBLq2-&amp;export&#x3D;download" />
    <meta property="article:published_time" content="2018-04-24T01:00:00.000Z" />
    <meta property="article:modified_time" content="2018-04-24T01:00:00.000Z" />
    <meta property="article:tag" content="deep learning" />
    <meta property="article:tag" content="perceptron" />
    
    <meta property="article:publisher" content="https://www.facebook.com/vietnamlab.vn" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Đi tìm cội nguồn của DeepLearning - Perceptron" />
    <meta name="twitter:description" content="Hẳn là ai cũng biết sông bắt nguồn từ suối, các hồ nước từ độ cao lớn hơn. Và chắc hẳn nhiều người đã biết đến DeepLearning hoặc đã, đang làm việc với DeepLearning tuy nhiên bạn có biết nguồn gốc của DeepLearning(Neural Network)　từ đâu mà có không" />
    <meta name="twitter:url" content="https://blog.vietnamlab.vn/di-tim-coi-nguon-cua-deeplearning-perceptron/" />
    <meta name="twitter:image" content="https://drive.google.com/uc?id&#x3D;1mlsY5OD58Y9jLMDA9ikW4CNRkcZBLq2-&amp;export&#x3D;download" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="T.T.T" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="deep learning, perceptron" />
    <meta property="og:image:width" content="562" />
    <meta property="og:image:height" content="231" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "GMO-Z.com Vietnam Lab Center Technology Blog",
        "url": "https://blog.vietnamlab.vn/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://blog.vietnamlab.vn/favicon.ico",
            "width": 48,
            "height": 48
        }
    },
    "author": {
        "@type": "Person",
        "name": "T.T.T",
        "image": {
            "@type": "ImageObject",
            "url": "https://drive.google.com/uc?id=0B05rqFCwNCjkRXIxZVdxdFhMb28&export=download"
        },
        "url": "https://blog.vietnamlab.vn/author/thanhtt/",
        "sameAs": []
    },
    "headline": "Đi tìm cội nguồn của DeepLearning - Perceptron",
    "url": "https://blog.vietnamlab.vn/di-tim-coi-nguon-cua-deeplearning-perceptron/",
    "datePublished": "2018-04-24T01:00:00.000Z",
    "dateModified": "2018-04-24T01:00:00.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://drive.google.com/uc?id=1mlsY5OD58Y9jLMDA9ikW4CNRkcZBLq2-&export=download",
        "width": 562,
        "height": 231
    },
    "keywords": "deep learning, perceptron",
    "description": "Hẳn là ai cũng biết sông bắt nguồn từ suối, các hồ nước từ độ cao lớn hơn. Và\nchắc hẳn nhiều người đã biết đến DeepLearning hoặc đã, đang làm việc với\nDeepLearning tuy nhiên bạn có biết nguồn gốc của DeepLearning(Neural Network)　từ\nđâu mà có không ?\n\nĐó chính là Perceptron algorithm, bài viết này mình sẽ giải thích cặn kẽ với các\nbạn Perceptron là gì? Tại sao nó lại là cội nguồn của DeepLearning.\n\nĐối tượng bài viết:\n\n * Nếu bạn muốn tìm hiểu DeepLearning mà chưa biết bắt đầu từ đâu.\n * Nếu bạn ",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://blog.vietnamlab.vn/"
    }
}
    </script>

    <meta name="generator" content="Ghost 3.36" />
    <link rel="alternate" type="application/rss+xml" title="GMO-Z.com Vietnam Lab Center Technology Blog" href="../../rss/index.html" />

    <style amp-custom>
    *,
    *::before,
    *::after {
        box-sizing: border-box;
    }

    html {
        overflow-x: hidden;
        overflow-y: scroll;
        font-size: 62.5%;
        -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
    }

    body {
        min-height: 100vh;
        margin: 0;
        padding: 0;
        color: #3a4145;
        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Open Sans,Helvetica Neue,sans-serif;
        font-size: 1.7rem;
        line-height: 1.55em;
        font-weight: 400;
        font-style: normal;
        background: #fff;
        scroll-behavior: smooth;
        overflow-x: hidden;
        -webkit-font-smoothing: antialiased;
        -moz-osx-font-smoothing: grayscale;
    }

    p,
    ul,
    ol,
    li,
    dl,
    dd,
    hr,
    pre,
    form,
    table,
    video,
    figure,
    figcaption,
    blockquote {
        margin: 0;
        padding: 0;
    }

    ul[class],
    ol[class] {
        padding: 0;
        list-style: none;
    }

    img {
        display: block;
        max-width: 100%;
    }

    input,
    button,
    select,
    textarea {
        font: inherit;
        -webkit-appearance: none;
    }

    fieldset {
        margin: 0;
        padding: 0;
        border: 0;
    }

    label {
        display: block;
        font-size: 0.9em;
        font-weight: 700;
    }

    hr {
        position: relative;
        display: block;
        width: 100%;
        height: 1px;
        border: 0;
        border-top: 1px solid currentcolor;
        opacity: 0.1;
    }

    ::selection {
        text-shadow: none;
        background: #cbeafb;
    }

    mark {
        background-color: #fdffb6;
    }

    small {
        font-size: 80%;
    }

    sub,
    sup {
        position: relative;
        font-size: 75%;
        line-height: 0;
        vertical-align: baseline;
    }
    sup {
        top: -0.5em;
    }
    sub {
        bottom: -0.25em;
    }

    ul li + li {
        margin-top: 0.6em;
    }

    a {
        color: #1292EE;
        text-decoration-skip-ink: auto;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
        margin: 0;
        font-weight: 700;
        color: #121212;
        line-height: 1.4em;
    }

    h1 {
        font-size: 3.4rem;
        line-height: 1.1em;
    }

    h2 {
        font-size: 2.4rem;
        line-height: 1.2em;
    }

    h3 {
        font-size: 1.8rem;
    }

    h4 {
        font-size: 1.7rem;
    }

    h5 {
        font-size: 1.6rem;
    }

    h6 {
        font-size: 1.6rem;
    }

    amp-img {
        height: 100%;
        width: 100%;
        max-width: 100%;
        max-height: 100%;
    }

    amp-img img {
        object-fit: cover;
    }

    .page-header {
        padding: 50px 5vmin 30px;
        text-align: center;
        font-size: 2rem;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }

    .page-header a {
        color: #121212;
        font-weight: 700;
        text-decoration: none;
        font-size: 1.6rem;
        letter-spacing: -0.1px;
    }

    .post {
        max-width: 680px;
        margin: 0 auto;
    }

    .post-header {
        margin: 0 5vmin 5vmin;
        text-align: center;
    }

    .post-meta {
        margin: 1rem 0 0 0;
        text-transform: uppercase;
        color: #738a94;
        font-weight: 500;
        font-size: 1.3rem;
    }

    .post-image {
        margin: 0 0 5vmin;
    }

    .post-image img {
        display: block;
        width: 100%;
        height: auto;
    }

    .post-content {
        padding: 0 5vmin;
    }

    .post-content > * + * {
        margin-top: 1.5em;
    }

    .post-content [id]:not(:first-child) {
        margin: 2em 0 0;
    }

    .post-content > [id] + * {
        margin-top: 1rem;
    }

    .post-content [id] + .kg-card,
    .post-content blockquote + .kg-card {
        margin-top: 40px;
    }

    .post-content > ul,
    .post-content > ol,
    .post-content > dl {
        padding-left: 1.9em;
    }

    .post-content hr {
        margin-top: 40px;
    }

    .post .post-content hr + * {
        margin-top: 40px;
    }

    .post-content amp-img {
        background-color: #f8f8f8;
    }

    .post-content blockquote {
        position: relative;
        font-style: italic;
    }

    .post-content blockquote::before {
        content: "";
        position: absolute;
        left: -1.5em;
        top: 0;
        bottom: 0;
        width: 0.3rem;
        background: #000;
    }

    .post-content :not(.kg-card):not([id]) + .kg-card {
        margin-top: 40px;
    }

    .post-content .kg-card + :not(.kg-card) {
        margin-top: 40px;
    }

    .kg-card figcaption {
        padding: 1.5rem 1.5rem 0;
        text-align: center;
        font-weight: 500;
        font-size: 1.3rem;
        line-height: 1.4em;
        opacity: 0.6;
    }

    .kg-card figcaption strong {
        color: rgba(0,0,0,0.8);
    }

    .post-content :not(pre) code {
        vertical-align: middle;
        padding: 0.15em 0.4em 0.15em;
        border: #e1eaef 1px solid;
        font-weight: 400;
        font-size: 0.9em;
        line-height: 1em;
        color: #dc0050;
        background: #f0f6f9;
        border-radius: 0.25em;
    }

    .post-content > pre {
        overflow: scroll;
        padding: 16px 20px;
        color: #fff;
        background: #1F2428;
        border-radius: 5px;
        box-shadow: 0 2px 6px -2px rgba(0,0,0,.1), 0 0 1px rgba(0,0,0,.4);
    }

    .kg-embed-card {
        display: flex;
        flex-direction: column;
        align-items: center;
        width: 100%;
    }

    .kg-image-card img {
        margin: auto;
    }

    .kg-gallery-card + .kg-gallery-card {
        margin-top: 0.75em;
    }

    .kg-gallery-container {
        position: relative;
    }

    .kg-gallery-row {
        display: flex;
        flex-direction: row;
        justify-content: center;
    }

    .kg-gallery-image {
        width: 100%;
        height: 100%;
    }

    .kg-gallery-row:not(:first-of-type) {
        margin: 0.75em 0 0 0;
    }

    .kg-gallery-image:not(:first-of-type) {
        margin: 0 0 0 0.75em;
    }

    .kg-bookmark-card,
    .kg-bookmark-publisher {
        position: relative;
    }

    .kg-bookmark-container,
    .kg-bookmark-container:hover {
        display: flex;
        flex-wrap: wrap;
        flex-direction: row-reverse;
        color: currentColor;
        background: rgba(255,255,255,0.6);
        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Open Sans,Helvetica Neue,sans-serif;
        text-decoration: none;
        border-radius: 5px;
        box-shadow: 0 2px 6px -2px rgba(0, 0, 0, 0.1), 0 0 1px rgba(0, 0, 0, 0.4);
        overflow: hidden;
    }

    .kg-bookmark-content {
        flex-basis: 0;
        flex-grow: 999;
        padding: 20px;
        order: 1;
    }

    .kg-bookmark-title {
        font-weight: 600;
        font-size: 1.5rem;
        line-height: 1.3em;
    }

    .kg-bookmark-description {
        display: -webkit-box;
        max-height: 45px;
        margin: 0.5em 0 0 0;
        font-size: 1.4rem;
        line-height: 1.55em;
        overflow: hidden;
        opacity: 0.8;
        -webkit-line-clamp: 2;
        -webkit-box-orient: vertical;
    }

    .kg-bookmark-metadata {
        margin-top: 20px;
    }

    .kg-bookmark-metadata {
        display: flex;
        align-items: center;
        font-weight: 500;
        font-size: 1.3rem;
        line-height: 1.3em;
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
    }

    .kg-bookmark-description {
        display: -webkit-box;
        -webkit-box-orient: vertical;
        -webkit-line-clamp: 2;
        overflow: hidden;
    }

    .kg-bookmark-metadata amp-img {
        width: 18px;
        height: 18px;
        max-width: 18px;
        max-height: 18px;
        margin-right: 10px;
    }

    .kg-bookmark-thumbnail {
        display: flex;
        flex-basis: 20rem;
        flex-grow: 1;
        justify-content: flex-end;
    }

    .kg-bookmark-thumbnail amp-img {
        max-height: 200px;
    }

    .kg-bookmark-author {
        white-space: nowrap;
        text-overflow: ellipsis;
        overflow: hidden;
    }

    .kg-bookmark-publisher::before {
        content: "•";
        margin: 0 .5em;
    }

    .kg-width-full.kg-card-hascaption {
        display: grid;
        grid-template-columns: inherit;
    }

    .post-content table {
        border-collapse: collapse;
        width: 100%;
    }

    .post-content th {
        padding: 0.5em 0.8em;
        text-align: left;
        font-size: .75em;
        text-transform: uppercase;
    }

    .post-content td {
        padding: 0.4em 0.7em;
    }

    .post-content tbody tr:nth-child(2n + 1) {
        background-color: rgba(0,0,0,0.1);
        padding: 1px;
    }

    .post-content tbody tr:nth-child(2n + 2) td:last-child {
        box-shadow:
            inset 1px 0 rgba(0,0,0,0.1),
            inset -1px 0 rgba(0,0,0,0.1);
    }

    .post-content tbody tr:nth-child(2n + 2) td {
        box-shadow: inset 1px 0 rgba(0,0,0,0.1);
    }

    .post-content tbody tr:last-child {
        border-bottom: 1px solid rgba(0,0,0,.1);
    }

    .page-footer {
        padding: 60px 5vmin;
        margin: 60px auto 0;
        text-align: center;
        background-color: #f8f8f8;
    }

    .page-footer h3 {
        margin: 0.5rem 0 0 0;
    }

    .page-footer p {
        max-width: 500px;
        margin: 1rem auto 1.5rem;
        font-size: 1.7rem;
        line-height: 1.5em;
        color: rgba(0,0,0,0.6)
    }

    .powered {
        display: inline-flex;
        align-items: center;
        margin: 30px 0 0;
        padding: 6px 9px 6px 6px;
        border: rgba(0,0,0,0.1) 1px solid;
        font-size: 12px;
        line-height: 12px;
        letter-spacing: -0.2px;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans", "Helvetica Neue", sans-serif;
        font-weight: 500;
        color: #222;
        text-decoration: none;
        background: #fff;
        border-radius: 6px;
    }

    .powered svg {
        height: 16px;
        width: 16px;
        margin: 0 6px 0 0;
    }

    @media (max-width: 600px) {
        body {
            font-size: 1.6rem;
        }
        h1 {
            font-size: 3rem;
        }

        h2 {
            font-size: 2.2rem;
        }
    }

    @media (max-width: 400px) {
        h1 {
            font-size: 2.6rem;
            line-height: 1.15em;
        }
        h2 {
            font-size: 2rem;
            line-height: 1.2em;
        }
        h3 {
            font-size: 1.7rem;
        }
    }
    </style>

    <style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
    <script async src="https://cdn.ampproject.org/v0.js"></script>

    

</head>

<body class="amp-template">
    <header class="page-header">
        <a href="../../index.html">
                GMO-Z.com Vietnam Lab Center Technology Blog
        </a>
    </header>

    <main class="content" role="main">
        <article class="post">

            <header class="post-header">
                <h1 class="post-title">Đi tìm cội nguồn của DeepLearning - Perceptron</h1>
                <section class="post-meta">
                    T.T.T -
                    <time class="post-date" datetime="2018-04-24">24 Apr 2018</time>
                </section>
            </header>
            <figure class="post-image">
                <amp-img src="https://drive.google.com/uc?id&#x3D;1mlsY5OD58Y9jLMDA9ikW4CNRkcZBLq2-&amp;export&#x3D;download" width="600" height="340" layout="responsive"></amp-img>
            </figure>
            <section class="post-content">

                <p>Hẳn là ai cũng biết sông bắt nguồn từ suối, các hồ nước từ độ cao lớn hơn. Và chắc hẳn nhiều người đã biết đến DeepLearning hoặc đã, đang làm việc với DeepLearning tuy nhiên bạn có biết nguồn gốc của DeepLearning(Neural Network)　từ đâu mà có không ?</p>
<p>Đó chính là Perceptron algorithm, bài viết này mình sẽ giải thích cặn kẽ với các bạn Perceptron là gì? Tại sao nó lại là cội nguồn của DeepLearning.</p>
<p>Đối tượng bài viết:</p>
<ul>
<li>Nếu bạn muốn tìm hiểu DeepLearning mà chưa biết bắt đầu từ đâu.</li>
<li>Nếu bạn đang làm việc với DeepLearning nhưng lại chưa nắm được kiến thức cơ bản.</li>
</ul>
<h3 id="perceptronlg">Perceptron là gì?</h3>
<p>Perceptron sẽ nhận input đầu vào là nhiều tín hiệu khác nhau, output là 1 tín hiệu duy nhất. "Tín hiệu" ở đây bạn có thể tưởng tượng như một vật nào đó có dòng chảy như dòng điện hay sông chẳng hạn. Dòng điện thì sẽ được truyền đi theo đường dây, việc dòng điện được truyền đi có bản chất là dòng dịch chuyển các electron dựa trên sự chênh lệch hiệu điện thế. Khác với dòng điện, tín hiệu của Perceptron mang 2 giá trị "1/0", 1 mang ý nghĩa là truyền tín hiệu, 0 là không truyền tín hiệu.</p>
<p>Như ví dụ dưới đây biểu diễn 1 Perceptron nhận 2 tín hiệu đầu vào.</p>
<p><amp-img src="https://drive.google.com/uc?id=1ZlaQOrZb2SJvXpRAyQoibtK2OBUO29mU&amp;export=download" alt width="239" height="211" layout="fixed"></amp-img></p>
<ul>
<li>x1, x2 là tín hiệu input</li>
<li>y là tín hiệu output</li>
<li>w1, w2 là weight</li>
<li>○ có thể gọi là node hoặc neuron</li>
</ul>
<p>Bạn có đang thắc mắc weight là cái khỉ gì không ?<br />
Hiểu đơn giản giống như dòng điện, weight chính là trở kháng. Trở kháng càng cao thì dòng điện càng khó được truyền đi phải không. Tuy nhiên weight của Perceptron thì ngược lại, giá trị càng cao thì tín hiệu càng dễ được truyền đi.</p>
<p>Khi tín hiệu x được gửi đến neuron thì tại mỗi neuron sẽ nhân với weight $ ( x_1 \omega _1,  x_2 \omega _2) $. Output sẽ được tính đơn giản như sau:</p>
<p><amp-img src="https://drive.google.com/uc?id=1DSvhIKBRnzzA1P2FqeCn8SpmWIVBIX4-&amp;export=download" alt width="223" height="69" layout="fixed"></amp-img></p>
<p>$  \theta  $ có tên gọi là ngưỡng (threshold). Chỉ khi nào giá trị vượt ngưỡng thì y mới return về 1. Vì vậy chức năng của Perceptron chính là điều khiển các tín hiệu. Chốt lại là với weight càng lớn thì độ quan trọng của tín hiệu càng cao.</p>
<h3 id="mchlogicngin">Mạch logic đơn giản</h3>
<h4 id="mchand">Mạch AND</h4>
<p>Phần trên mình đã trình bày nguyên lý hoạt động của Perceptron, tiếp theo là ứng dụng của nó ra sao. Chắc hẳn bạn cũng biết mạch AND là gì. Đơn giản là mạch AND có 2 input và 1 output, chỉ khi input $ x_1, x_2 $ bằng 1 thì output mới bằng 1.</p>
<p><amp-img src="https://drive.google.com/uc?id=1cVXvGwxt4YPzA0E39kJDNUe_1ZdBLx9H&amp;export=download" alt="-and-gate" width="359" height="222" layout="responsive"></amp-img></p>
<p>Vậy thì nếu muốn biểu diễn mạch AND bằng Perceptron thì sẽ làm thế nào ? Thực chất công việc cần làm là lựa chọn $ ( \omega _1, \omega _2, \theta ) $ sao cho thỏa mãn như hình. Ví dụ $ ( \omega _1, \omega _2, \theta ) $ = (0.5, 0.5, 0.7). Với parameter này, chỉ khi cả $ x_1, x_2 $ bằng 1 thì tổng mới $ &gt; \theta $ và output y = 1.</p>
<p><amp-img src="https://drive.google.com/uc?id=1Q_ZZtVBI-uRcE_afjuHs9sbPzPfw3_o2&amp;export=download" alt="AND-perceptron" width="693" height="272" layout="responsive"></amp-img></p>
<h4 id="mchnandvor">Mạch NAND và OR</h4>
<p>NAND có ý nghĩa là Not AND nên output sẽ ngược lại so với AND. Tương tự như trên để biểu diễn mạch NAND bằng Perceptron thì cần lựa chọn parameter $ ( \omega _1, \omega _2, \theta ) $. Ví dụ parameter là $ ( \omega _1, \omega _2, \theta ) = (-0.5, -0.5, -0.7)$</p>
<p><amp-img src="https://drive.google.com/uc?id=1SNk37f_4Qy4n35nG5pNsZPX1uvLJ0WPw&amp;export=download" alt="NAND-perceptron-1" width="679" height="276" layout="responsive"></amp-img></p>
<p>Cũng không có khó khăn gì đúng không các bạn ^^. Với mạch OR thì như sau:</p>
<p><amp-img src="https://drive.google.com/uc?id=10mreci-t8KZ0nH4NE30W70oRYJ7tHxHI&amp;export=download" alt="OR-gate" width="359" height="222" layout="responsive"></amp-img></p>
<p>Vậy bạn thử suy nghĩ xem nên chọn parameter như thế nào cho phù hợp và để lại comment phía ↓ nhé. ^^</p>
<p><em>Ở đây, việc chọn parameter cho Perceptron hoàn toàn bằng tay. Công việc của Machinelearning sẽ thay chúng ta lựa chọn parameter cho phù hợp và công việc của chúng ta là code model Perceptron</em></p>
<p>Ở trên mình đã nói đến 3 mạch cơ bản là AND, NAND, OR. Về bản chất chúng hoàn toàn giống nhau, sự khác nhau chỉ là ở parameter Perceptron $ ( \omega _1, \omega _2, \theta ) $  mà thôi. Chính vì vậy với 1 model duy nhất, bằng việc thay đổi parameter thích hợp thì sẽ  transform được mạch AND, NAND hay OR.</p>
<h4 id="implementperceptron">Implement Perceptron</h4>
<h5 id="weightvbias">Weight và Bias</h5>
<p>Biểu diễn lại công thức đầu tiên của Perceptron như sau:</p>
<p><amp-img src="https://drive.google.com/uc?id=10IxvYky6OS8hb4_bSwwK4DrGQUSwJ_jZ&amp;export=download" alt="----------2018-04-15-12.33.02" width="246" height="66" layout="fixed"></amp-img></p>
<p>b chính là threshold ở công thức trên, và ở đây thay vì gọi như vậy sẽ được gọi là bias, vì threshold bây giờ sẽ là 0.  $ \omega _1, \omega _2 $ sẽ là weight. Chức năng của bias và weight đương nhiên là khác nhau. Với chức năng của weight như đã nói ở trên là quyết định độ quan trọng của mỗi input, còn bias có chức năng tương tự như ngưỡng (threshold).</p>
<p>Chú ý:</p>
<ul>
<li>Tùy trường hợp, tài liệu mà $ \omega _1, \omega _2, b $ cùng được gọi là weight.</li>
</ul>
<h5 id="implementandviweightvbias">Implement AND với weight và bias.</h5>
<pre><code class="language-python"># coding: utf-8
import numpy as np

def AND(x1, x2):
    x = np.array([x1, x2])　 #input
    w = np.array([0.5, 0.5]) #weight
    b = -0.7 #bias
    tmp = np.sum(w*x) + b
    if tmp &lt;= 0:
        return 0
    else:
        return 1

if __name__ == '__main__':
    for xs in [(0, 0), (1, 0), (0, 1), (1, 1)]:
        y = AND(xs[0], xs[1])
        print(str(xs) + " -&gt; " + str(y))
</code></pre>
<h5 id="implementnandvor">Implement NAND và OR</h5>
<pre><code class="language-python">
# coding: utf-8
import numpy as np


def NAND(x1, x2):
    x = np.array([x1, x2])
    w = np.array([-0.5, -0.5])
    b = 0.7
    tmp = np.sum(w*x) + b
    if tmp &lt;= 0:
        return 0
    else:
        return 1

def OR(x1, x2):
    x = np.array([x1, x2])
    w = np.array([0.5, 0.5])
    b = -0.2
    tmp = np.sum(w*x) + b
    if tmp &lt;= 0:
        return 0
    else:
        return 1
        
</code></pre>
<h4 id="perceptronnhiutng">Perceptron nhiều tầng</h4>
<p>Perceptron có thể biểu diễn được mạch AND, NAND, OR nhưng lại không thể biểu diễn được mạch XOR. Không tin bạn thử làm xem :)). Thực ra sự bá đạo của Perceptron là có thể chồng được nhiều tầng lên nhau. Với việc xếp chồng nhiều tầng, Perceptron sẽ biểu diễn được mạch XOR.</p>
<h5 id="kthpccmchcsn">Kết hợp các mạch có sẵn</h5>
<p>Mạch XOR:</p>
<p><amp-img src="https://drive.google.com/uc?id=1f40V0YqzOWd-dJyHHllRzU2VtV6hFl9J&amp;export=download" alt="-xor-gate" width="316" height="207" layout="responsive"></amp-img></p>
<p>Tạo mạch XOR có nhiều cách nhưng cách đơn giản nhất là kết hợp từ các mạch AND, NAND, OR có sẵn.</p>
<pre><code class="language-python">def XOR(x1,x2):
    gate1 = NAND(x1,x2)
    gate2 = OR(x1,x2)
    y = AND(gate1, gate2)
    return y
</code></pre>
<p><amp-img src="https://drive.google.com/uc?id=14258GQFjOXVnUwcnmsjHwrAVSOQ0OJyC&amp;export=download" alt="XOR-Per" width="485" height="214" layout="responsive"></amp-img></p>
<p>Lúc này sơ đồ luồng di chuyển sẽ như sau:</p>
<p><amp-img src="https://drive.google.com/uc?id=13m7TMYKTJqAn8ywjXdHeGAcRHRV1iE3o&amp;export=download" alt width="611" height="355" layout="responsive"></amp-img></p>
<h3 id="tngkt">Tổng kết</h3>
<p>Trên đây mình đã giới thiệu với các bạn Perceptron là gì. Ứng dụng nó ra sao. Đây là một thuật toán cực kỳ đơn giản nên chắc hẳn các bạn đã có thể hiểu được ngay. Bài viết sau mình sẽ giới thiệu về nền tảng của neural network. Và tất nhiên newral network sẽ được xây dựng dựa trên Perceptron nên hiểu nguyên lý hoạt động của Perceptron rất quan trọng.</p>
<p>Hẹn gặp lại các bạn ở bài viết sau.</p>
<h3 id="linkthamkho">Link tham khảo</h3>
<p>Cuốn sách này khá hay và chi tiết về Deeplearning các bạn có thể tham khảo nhé. (Tiếc là không có bản english)<br />
<a href="https://www.oreilly.co.jp/books/9784873117584/">https://www.oreilly.co.jp/books/9784873117584/</a></p>


            </section>

        </article>
    </main>
    <footer class="page-footer">
        <h3>GMO-Z.com Vietnam Lab Center Technology Blog</h3>
            <p>Blog chia sẻ kỹ thuật của thành viên công ty GMO-Z.com Vietnam Lab Center</p>
        <p><a href="../../index.html">Read more posts →</a></p>
        <a class="powered" href="https://ghost.org" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 156 156"><g fill="none" fill-rule="evenodd"><rect fill="#15212B" width="156" height="156" rx="27"/><g transform="translate(36 36)" fill="#F6F8FA"><path d="M0 71.007A4.004 4.004 0 014 67h26a4 4 0 014 4.007v8.986A4.004 4.004 0 0130 84H4a4 4 0 01-4-4.007v-8.986zM50 71.007A4.004 4.004 0 0154 67h26a4 4 0 014 4.007v8.986A4.004 4.004 0 0180 84H54a4 4 0 01-4-4.007v-8.986z"/><rect y="34" width="84" height="17" rx="4"/><path d="M0 4.007A4.007 4.007 0 014.007 0h41.986A4.003 4.003 0 0150 4.007v8.986A4.007 4.007 0 0145.993 17H4.007A4.003 4.003 0 010 12.993V4.007z"/><rect x="67" width="17" height="17" rx="4"/></g></g></svg> Published with Ghost</a>
    </footer>
    
</body>
</html>
